{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tokenizer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open \"SMSSpamCollection\" file to read the data\n",
    "# For each line in the file, split the line into two parts: the label (first word) and the message (the rest of the line)\n",
    "# Store the label in the list \"labels\" and the tokenized message in the list \"messages\"\n",
    "labels = []\n",
    "messages = []\n",
    "\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "with open(\"SMSSpamCollection\") as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        label, message = line.split(\"\\t\", 1)\n",
    "        labels.append(label)\n",
    "        messages.append(tokenizer.tokenize(message.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham\n",
      "['go', 'until', 'jurong', 'point', ',', 'crazy', '..', 'available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', '...', 'cine', 'there', 'got', 'amore', 'wat', '...']\n",
      "ham\n",
      "['ok', 'lar', '...', 'joking', 'wif', 'u', 'oni', '...']\n",
      "spam\n",
      "['free', 'entry', 'in', '2', 'a', 'wkly', 'comp', 'to', 'win', 'fa', 'cup', 'final', 'tkts', '21st', 'may', '2005', '.', 'text', 'fa', 'to', '87121', 'to', 'receive', 'entry', 'question', '(', 'std', 'txt', 'rate', ')', 't', '&', 'c', \"'\", 's', 'apply', '08452810075over18', \"'\", 's']\n",
      "ham\n",
      "['u', 'dun', 'say', 'so', 'early', 'hor', '...', 'u', 'c', 'already', 'then', 'say', '...']\n",
      "ham\n",
      "['nah', 'i', 'don', \"'\", 't', 'think', 'he', 'goes', 'to', 'usf', ',', 'he', 'lives', 'around', 'here', 'though']\n"
     ]
    }
   ],
   "source": [
    "# Print the first 5 messages\n",
    "for i in range(5):\n",
    "    print(labels[i])\n",
    "    print(messages[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(messages, labels):\n",
    "    # Split the dataset into training and testing sets with a 80-20 split\n",
    "    # Return the training and testing sets for both messages and labels\n",
    "    # TODO: Change split to 80-20 (0.8), currently set to 0.2 for code testing\n",
    "    split_index = int(0.8 * len(messages))\n",
    "    train_messages = messages[:split_index]\n",
    "    test_messages = messages[split_index:]\n",
    "    train_labels = labels[:split_index]\n",
    "    test_labels = labels[split_index:]\n",
    "    return train_messages, test_messages, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_messages, test_messages, train_labels, test_labels = split_dataset(messages, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_frequency(word, document):\n",
    "    # Count the frequency of the word in the document (list of words)\n",
    "    return document.count(word) / len(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_frequency(word, documents):\n",
    "    # Count the number of documents containing the word\n",
    "    count = 0\n",
    "    for document in documents:\n",
    "        if word in document:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(word, documents):\n",
    "    # Calculate the inverse document frequency of the word\n",
    "    df = document_frequency(word, documents)\n",
    "    # If the word is not in any document, return 0\n",
    "    # This prevents division by zero errors when calculating idf\n",
    "    if df == 0:\n",
    "        return 0\n",
    "    return np.log(len(documents) / (document_frequency(word, documents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(word, document, documents):\n",
    "    # Calculate the term frequency-inverse document frequency of the word\n",
    "    return term_frequency(word, document) * idf(word, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_vectorizor(messages):\n",
    "    # Create a TF-IDF vector for each document\n",
    "    # Return the list of TF-IDF vectors\n",
    "    vectors = []\n",
    "    for message in messages:\n",
    "        vector = []\n",
    "        for word in message:\n",
    "            vector.append(tf_idf(word, message, messages))\n",
    "        vectors.append(vector)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = tf_idf_vectorizor(train_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['go', 'until', 'jurong', 'point', ',', 'crazy', '..', 'available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', '...', 'cine', 'there', 'got', 'amore', 'wat', '...']\n",
      "[0.1279150421400878, 0.2176927489283138, 0.35011165852614484, 0.2501993554928794, 0.05978210845106636, 0.25417061298472626, 0.10773202686101135, 0.23206110252380252, 0.1378720668258631, 0.08049501253520311, 0.27545501397497585, 0.156595371061921, 0.16549429190767345, 0.20980766561004177, 0.28305174550805734, 0.1719172369004759, 0.32123052600281377, 0.17334288039168272, 0.26903206898217347, 0.13304973549108565, 0.13282266862577047, 0.35011165852614484, 0.16700961041479323, 0.17334288039168272]\n",
      "['ok', 'lar', '...', 'joking', 'wif', 'u', 'oni', '...']\n",
      "[0.368955168882722, 0.6171179877284687, 0.5200286411750482, 0.9636915780084414, 0.6822801031826295, 0.23767376676088595, 0.9130084394949208, 0.5200286411750482]\n",
      "['free', 'entry', 'in', '2', 'a', 'wkly', 'comp', 'to', 'win', 'fa', 'cup', 'final', 'tkts', '21st', 'may', '2005', '.', 'text', 'fa', 'to', '87121', 'to', 'receive', 'entry', 'question', '(', 'std', 'txt', 'rate', ')', 't', '&', 'c', \"'\", 's', 'apply', '08452810075over18', \"'\", 's']\n",
      "[0.08173702684662798, 0.28561366464468, 0.04953539232935576, 0.06629663191446852, 0.03948517670707885, 0.15911423659721172, 0.16213431443455487, 0.09122848599369378, 0.11090108617235274, 0.3953606473880785, 0.16213431443455487, 0.14436130980481268, 0.17990731906429708, 0.18728378246049657, 0.11961564580369509, 0.18728378246049657, 0.01781328904594837, 0.08802221807824297, 0.3953606473880785, 0.09122848599369378, 0.17990731906429708, 0.09122848599369378, 0.13094469073392687, 0.28561366464468, 0.1399548929605394, 0.11178534709725452, 0.15911423659721172, 0.08967705195356532, 0.13191239145143577, 0.11514504613331615, 0.06629663191446852, 0.06287275005230128, 0.09895859031685827, 0.07300177074659828, 0.12263654513965719, 0.13094469073392687, 0.19768032369403926, 0.07300177074659828, 0.12263654513965719]\n",
      "['u', 'dun', 'say', 'so', 'early', 'hor', '...', 'u', 'c', 'already', 'then', 'say', '...']\n",
      "[0.2925215590903212, 0.3645475506536793, 0.6224570735289054, 0.19843337762649677, 0.3900365611117133, 0.6463599849713444, 0.3200176253384912, 0.2925215590903212, 0.2968757709505748, 0.3163246433445451, 0.24314867612060265, 0.6224570735289054, 0.3200176253384912]\n",
      "['nah', 'i', 'don', \"'\", 't', 'think', 'he', 'goes', 'to', 'usf', ',', 'he', 'lives', 'around', 'here', 'though']\n",
      "[0.3812559194770894, 0.06156871263830827, 0.22339787920782347, 0.08897090809741666, 0.16159804029151703, 0.23549692602486505, 0.43533735984991895, 0.33197733445432254, 0.07412314486987619, 0.4035481034732602, 0.08967316267659954, 0.43533735984991895, 0.4385240902192241, 0.2819287191573031, 0.23734435116496158, 0.33793422069209283]\n"
     ]
    }
   ],
   "source": [
    "# Print the first 5 tf-idf vectors\n",
    "for i in range(5):\n",
    "    print(train_messages[i])\n",
    "    print(train_vectors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_vectorizor(messages):\n",
    "    num_messages = len(messages)                        # Count the number of messages provided in the input\n",
    "\n",
    "    document_frequencies = {}                           # Store the number of messages which contain the specified word\n",
    "    \n",
    "    words_in_messages = []                              # Convert each message in messages into a list of dictonaries\n",
    "\n",
    "    for message in messages:                            # For each message in messages:\n",
    "        words_in_message = {}                               # Store the count of each word in the message in a dictionary\n",
    "        unique_words = set(message)\n",
    "        for word in message:                            # For each word in the message:\n",
    "            if word in words_in_message:                    # If the word is already in the dictionary, increment the count\n",
    "                words_in_message[word] += 1\n",
    "            else:                                           # Otherwise, add the word to the dictionary with a count of 1\n",
    "                words_in_message[word] = 1\n",
    "        words_in_messages.append(words_in_message)\n",
    "        for word in unique_words:                       # Update the document frequencies for each unique word in the message\n",
    "            if word in document_frequencies:\n",
    "                document_frequencies[word] += 1\n",
    "            else:\n",
    "                document_frequencies[word] = 1\n",
    "\n",
    "    tf_idf_vectors = []                                 # Store the TF-IDF vectors for all messages\n",
    "    for i, message in enumerate(messages):              # For each message in messages:\n",
    "        tf_idf_vector = []                                  # Calculate the TF-IDF vector and store it in tf_idf_vectors\n",
    "        for word in message:\n",
    "            term_frequency = words_in_messages[i][word] / len(message)\n",
    "            document_frequency = document_frequencies[word]\n",
    "            inverse_document_frequency = np.log(num_messages / document_frequency)\n",
    "            tf_idf_vector.append(term_frequency * inverse_document_frequency)\n",
    "        tf_idf_vectors.append(tf_idf_vector)\n",
    "    \n",
    "    return tf_idf_vectors                               # Return the list of TF-IDF vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the optimized TF-IDF vectorizer\n",
    "train_vectors = tf_idf_vectorizor(train_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['go', 'until', 'jurong', 'point', ',', 'crazy', '..', 'available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', '...', 'cine', 'there', 'got', 'amore', 'wat', '...']\n",
      "[0.1279150421400878, 0.2176927489283138, 0.35011165852614484, 0.2501993554928794, 0.05978210845106636, 0.25417061298472626, 0.10773202686101135, 0.23206110252380252, 0.1378720668258631, 0.08049501253520311, 0.27545501397497585, 0.156595371061921, 0.16549429190767345, 0.20980766561004177, 0.28305174550805734, 0.1719172369004759, 0.32123052600281377, 0.17334288039168272, 0.26903206898217347, 0.13304973549108565, 0.13282266862577047, 0.35011165852614484, 0.16700961041479323, 0.17334288039168272]\n",
      "['ok', 'lar', '...', 'joking', 'wif', 'u', 'oni', '...']\n",
      "[0.368955168882722, 0.6171179877284687, 0.5200286411750482, 0.9636915780084414, 0.6822801031826295, 0.23767376676088595, 0.9130084394949208, 0.5200286411750482]\n",
      "['free', 'entry', 'in', '2', 'a', 'wkly', 'comp', 'to', 'win', 'fa', 'cup', 'final', 'tkts', '21st', 'may', '2005', '.', 'text', 'fa', 'to', '87121', 'to', 'receive', 'entry', 'question', '(', 'std', 'txt', 'rate', ')', 't', '&', 'c', \"'\", 's', 'apply', '08452810075over18', \"'\", 's']\n",
      "[0.08173702684662798, 0.28561366464468, 0.04953539232935576, 0.06629663191446852, 0.03948517670707885, 0.15911423659721172, 0.16213431443455487, 0.09122848599369378, 0.11090108617235274, 0.3953606473880785, 0.16213431443455487, 0.14436130980481268, 0.17990731906429708, 0.18728378246049657, 0.11961564580369509, 0.18728378246049657, 0.01781328904594837, 0.08802221807824297, 0.3953606473880785, 0.09122848599369378, 0.17990731906429708, 0.09122848599369378, 0.13094469073392687, 0.28561366464468, 0.1399548929605394, 0.11178534709725452, 0.15911423659721172, 0.08967705195356532, 0.13191239145143577, 0.11514504613331615, 0.06629663191446852, 0.06287275005230128, 0.09895859031685827, 0.07300177074659828, 0.12263654513965719, 0.13094469073392687, 0.19768032369403926, 0.07300177074659828, 0.12263654513965719]\n",
      "['u', 'dun', 'say', 'so', 'early', 'hor', '...', 'u', 'c', 'already', 'then', 'say', '...']\n",
      "[0.2925215590903212, 0.3645475506536793, 0.6224570735289054, 0.19843337762649677, 0.3900365611117133, 0.6463599849713444, 0.3200176253384912, 0.2925215590903212, 0.2968757709505748, 0.3163246433445451, 0.24314867612060265, 0.6224570735289054, 0.3200176253384912]\n",
      "['nah', 'i', 'don', \"'\", 't', 'think', 'he', 'goes', 'to', 'usf', ',', 'he', 'lives', 'around', 'here', 'though']\n",
      "[0.3812559194770894, 0.06156871263830827, 0.22339787920782347, 0.08897090809741666, 0.16159804029151703, 0.23549692602486505, 0.43533735984991895, 0.33197733445432254, 0.07412314486987619, 0.4035481034732602, 0.08967316267659954, 0.43533735984991895, 0.4385240902192241, 0.2819287191573031, 0.23734435116496158, 0.33793422069209283]\n"
     ]
    }
   ],
   "source": [
    "# Print the first 5 tf-idf vectors\n",
    "for i in range(5):\n",
    "    print(train_messages[i])\n",
    "    print(train_vectors[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
