{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import re to tokenize using RegEx\n",
    "import re\n",
    "# Import numpy for mathematical functions\n",
    "import numpy as np\n",
    "# Import Counter for counting data and defaultdict for storing data\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the label in the list \"labels\" and the untokenized message in the list \"messages\"\n",
    "labels = []\n",
    "messages = []\n",
    "\n",
    "# Open \"SMSSpamCollection\" file to read the data\n",
    "with open(\"SMSSpamCollection\") as file:\n",
    "    for line in file:\n",
    "        try:\n",
    "            # Clean the line of whitespace and split by first tab into label and message, then append to the lists\n",
    "            label, message = line.strip().split(\"\\t\", 1)\n",
    "            labels.append(label)\n",
    "            messages.append(message.lower())\n",
    "        # If an error occurs, print the error\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Store the tokenized messsages in the list \"tokenized_messages\"\n",
    "tokenized_messages = [re.findall(r'\\b\\w+\\b', message) for message in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given messages and (optionally) a vector size, return a list of TF-IDF vectors of a fixed size\n",
    "def tf_idf_vectorizor(messages, vector_size=20):\n",
    "    num_messages = len(messages)                        # Count the number of messages provided in the dataset\n",
    "\n",
    "    document_frequencies = {}                           # For all words in the dataset, store the number of messages that contain the word\n",
    "    \n",
    "    words_in_messages = []                              # Store all tokenized sentences as a list of dictionaries\n",
    "\n",
    "    for message in messages:                            \n",
    "        words_in_message = {}                           # Store the count of each word in the message as a dictionary\n",
    "        unique_words = set(message)\n",
    "        for word in message:                            \n",
    "            if word in words_in_message:                # If the word is already in the dictionary, increment the count\n",
    "                words_in_message[word] += 1\n",
    "            else:                                       # Otherwise, initialize the word in the dictionary to a count of 1\n",
    "                words_in_message[word] = 1\n",
    "        words_in_messages.append(words_in_message)\n",
    "        for word in unique_words:                       # Update the document frequencies for each unique word in the message\n",
    "            if word in document_frequencies:\n",
    "                document_frequencies[word] += 1\n",
    "            else:\n",
    "                document_frequencies[word] = 1\n",
    "\n",
    "    # Calculate the TF-IDF vectors for all messages and store values in dictionary\n",
    "    tf_idf_vectors = []\n",
    "    for i, message in enumerate(messages):\n",
    "        tf_idf_vector = {}\n",
    "        for word in message:\n",
    "            # Calculate term frequency\n",
    "            term_frequency = words_in_messages[i][word] / len(message)\n",
    "            # Calcualte document frequency\n",
    "            document_frequency = document_frequencies[word]\n",
    "            # Calculate inverse document frequency\n",
    "            inverse_document_frequency = np.log(num_messages / document_frequency)\n",
    "            # Calculate TF-IDF value\n",
    "            tf_idf_vector[word] = term_frequency * inverse_document_frequency\n",
    "        tf_idf_vectors.append(tf_idf_vector)\n",
    "\n",
    "    # Sort the document frequencies in order of most frequent to least frequent, then store the top n most frequent words\n",
    "    most_frequent_words = sorted(document_frequencies, key=document_frequencies.get, reverse=True)[:vector_size]\n",
    "\n",
    "    # Creates an n sized fixed length vector for each message\n",
    "    # Only stores the vectors of the n most frequent words or 0 if the word is not in the message\n",
    "    sentence_vectors = []\n",
    "    for i, message in enumerate(messages):\n",
    "        vector = []                                     \n",
    "        for word in most_frequent_words:                # Loop through each word in the most_frequent_words list\n",
    "            if word in tf_idf_vectors[i]:               \n",
    "                vector.append(tf_idf_vectors[i][word])  # If the word is in the TF-IDF vector, append the value to the vector\n",
    "            else:\n",
    "                vector.append(0)                        # Otherwise, append 0 to the vector to represent no frequency\n",
    "        sentence_vectors.append(vector)                 # Store the fixed length vector for the message at index i\n",
    "    \n",
    "    return sentence_vectors                             # Return the list of TF-IDF vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a dataset, split it into training and testing datasets based on the provided split percentage with a default of 80-20\n",
    "def split_dataset(messages, tokenized_messages, labels, vectors, split_percentage=0.8):\n",
    "    split_index = int(split_percentage * len(messages))\n",
    "    train_messages = messages[:split_index]\n",
    "    test_messages = messages[split_index:]\n",
    "    train_tokenized_messages = tokenized_messages[:split_index]\n",
    "    test_tokenized_messages = tokenized_messages[split_index:]\n",
    "    train_labels = labels[:split_index]\n",
    "    test_labels = labels[split_index:]\n",
    "    train_vectors = vectors[:split_index]\n",
    "    test_vectors = vectors[split_index:]\n",
    "    return train_messages, test_messages, train_tokenized_messages, test_tokenized_messages, train_labels, test_labels, train_vectors, test_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the k-NN algorithm using the Euclidean distance metric on two vectors\n",
    "def knn_classifier(test_vectors, train_vectors, train_labels, k):\n",
    "    # Store the predicted labels for all test messages\n",
    "    predicted_labels = []                               \n",
    "\n",
    "    # For each test message:\n",
    "    for test_vector in test_vectors:                    \n",
    "        distances = []                                  \n",
    "        # Calculate the distance matrix between the test message and all training messages\n",
    "        for train_vector in train_vectors:\n",
    "            # Use Euclidean distance through numpy\n",
    "            distance = np.linalg.norm(np.array(train_vector) - np.array(test_vector))\n",
    "            distances.append(distance)\n",
    "\n",
    "        # Sort the distances from smallest to largest and store the sorted indices\n",
    "        sorted_indices = np.argsort(distances)\n",
    "\n",
    "        # Store the k-nearest labels\n",
    "        nearest_labels = []\n",
    "        for i in range(k):\n",
    "            nearest_labels.append(train_labels[sorted_indices[i]])\n",
    "\n",
    "        \"\"\"ChatGPT assistance was used to write predict labels code using Counter function in place of loops\"\"\"\n",
    "        # Predict the label for the test message based on the majority label of the k-nearest labels\n",
    "        predicted_label = Counter(nearest_labels).most_common(1)[0][0]\n",
    "        predicted_labels.append(predicted_label)\n",
    "\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for train_naive_bayes\n",
    "# Tokenize a message into words\n",
    "def tokenize(message):\n",
    "    return re.findall(r'\\b\\w+\\b', message)  # extract words using regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the Naive-Bayes classifier\n",
    "def train_naive_bayes(labels, messages):\n",
    "    spam_count = labels.count('spam')                   # Count spam messages\n",
    "    ham_count = labels.count('ham')                     # Count ham messages\n",
    "    total_count = len(labels)                           # Total number of messages\n",
    "    \n",
    "    p_spam = spam_count / total_count                   # Prior probability of spam\n",
    "    p_ham = ham_count / total_count                     # Prior probability of ham\n",
    "    \n",
    "    spam_words = []\n",
    "    ham_words = []\n",
    "    \n",
    "    # tokenize messages and separate words into lists\n",
    "    for label, message in zip(labels, messages):\n",
    "        words = tokenize(message)\n",
    "        if label == 'spam':\n",
    "            spam_words.extend(words)\n",
    "        else:\n",
    "            ham_words.extend(words)\n",
    "    \n",
    "    # init word frequency counts with Laplace smoothing (ChatGPT)\n",
    "    spam_word_counts = defaultdict(lambda: 1)\n",
    "    ham_word_counts = defaultdict(lambda: 1)\n",
    "    \n",
    "    for word in spam_words:\n",
    "        spam_word_counts[word] += 1\n",
    "    for word in ham_words:\n",
    "        ham_word_counts[word] += 1\n",
    "    \n",
    "    total_spam_words = sum(spam_word_counts.values())  # total words in spam messages\n",
    "    total_ham_words = sum(ham_word_counts.values())  # total words in ham messages\n",
    "    \n",
    "    return p_spam, p_ham, spam_word_counts, ham_word_counts, total_spam_words, total_ham_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict if a message is spam or ham using Naive Bayes\n",
    "def predict_naive_bayes(message, p_spam, p_ham, spam_word_counts, ham_word_counts, total_spam_words, total_ham_words):\n",
    "    words = tokenize(message)\n",
    "    \n",
    "    \"\"\"ChatGPT assistance used to help prevent underflow via implementation of log probabilities\"\"\"\n",
    "    spam_prob = np.log(p_spam)\n",
    "    ham_prob = np.log(p_ham)\n",
    "    \n",
    "    for word in words:\n",
    "        spam_prob += np.log(spam_word_counts[word] / total_spam_words)\n",
    "        ham_prob += np.log(ham_word_counts[word] / total_ham_words)\n",
    "    \n",
    "    return 'spam' if spam_prob > ham_prob else 'ham'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the performance metrics for the k-NN classifier (TP, FP, TN, FN, accuracy, precision, recall, F1 score)\n",
    "def performance_metric(predicted_labels, actual_labels):\n",
    "    # Ensure the number of predicted labels and actual labels are the same\n",
    "    assert len(predicted_labels) == len(actual_labels)\n",
    "\n",
    "    # Initialize the performance metric counts\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "\n",
    "    # Loop through each pair of predicted and actual labels and update the counts\n",
    "    for i in range(len(predicted_labels)):\n",
    "        if predicted_labels[i] == \"spam\" and actual_labels[i] == \"spam\":\n",
    "            true_positives += 1\n",
    "        elif predicted_labels[i] == \"spam\" and actual_labels[i] == \"ham\":\n",
    "            false_positives += 1\n",
    "        elif predicted_labels[i] == \"ham\" and actual_labels[i] == \"ham\":\n",
    "            true_negatives += 1\n",
    "        elif predicted_labels[i] == \"ham\" and actual_labels[i] == \"spam\":\n",
    "            false_negatives += 1\n",
    "\n",
    "    \"\"\"ChatGPT assistance was used to add if-else statements to prevent division by zero\"\"\"\n",
    "    # Calculate accuracy, precision, recall, and F1 score\n",
    "    accuracy = (true_positives + true_negatives) / len(actual_labels)\n",
    "    precision = true_positives / (true_positives + false_positives) if true_positives + false_positives > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if true_positives + false_negatives > 0 else 0\n",
    "    f1_score = (2 * precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "    # Print the performance metrics\n",
    "    print(\"True Positives:\", true_positives)\n",
    "    print(\"False Positives:\", false_positives)\n",
    "    print(\"True Negatives:\", true_negatives)\n",
    "    print(\"False Negatives:\", false_negatives)\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameter values for classifiers (only split percentage affects Naive Bayes)\n",
    "split_percentage = 0.8                                  # Set training-testing split percentage for both classifiers\n",
    "fixed_vector_size = 30                                  # Set fixed vector size (AKA number of most frequent words in data to use) for k-NN\n",
    "num_neighbors = 1                                       # Set number of neighbors to look at for each test message for k-NN\n",
    "\n",
    "# Vectorize all messages for k-NN, vector size is the size of the fixed length TF-IDF vector to be returned\n",
    "vectors = tf_idf_vectorizor(tokenized_messages, vector_size=fixed_vector_size)\n",
    "\n",
    "# Split the dataset using the split percentage and get the training and testing messages, labels, and vectors\n",
    "train_messages, test_messages, train_tokenized_messages, test_tokenized_messages, train_labels, test_labels, train_vectors, test_vectors = split_dataset(messages, tokenized_messages, labels, vectors, split_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 116\n",
      "False Positives: 52\n",
      "True Negatives: 918\n",
      "False Negatives: 29\n",
      "Accuracy: 0.9274\n",
      "Precision: 0.6905\n",
      "Recall: 0.8000\n",
      "F1 Score: 0.7412\n"
     ]
    }
   ],
   "source": [
    "# Test the k-NN classifier\n",
    "predicted_labels = knn_classifier(test_vectors, train_vectors, train_labels, num_neighbors)\n",
    "\n",
    "# Print the performance metrics for the k-NN classifier\n",
    "performance_metric(predicted_labels, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Naive Bayes classifier\n",
    "p_spam, p_ham, spam_word_counts, ham_word_counts, total_spam_words, total_ham_words = train_naive_bayes(train_labels, train_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 141\n",
      "False Positives: 31\n",
      "True Negatives: 939\n",
      "False Negatives: 4\n",
      "Accuracy: 0.9686\n",
      "Precision: 0.8198\n",
      "Recall: 0.9724\n",
      "F1 Score: 0.8896\n"
     ]
    }
   ],
   "source": [
    "# Test Naive Bayes classifier\n",
    "predicted_labels = [predict_naive_bayes(message, p_spam, p_ham, spam_word_counts, ham_word_counts, total_spam_words, total_ham_words) for message in test_messages]\n",
    "\n",
    "# Print the performance metrics for the Naive Bayes classifier\n",
    "performance_metric(predicted_labels, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
