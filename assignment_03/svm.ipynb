{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded dataset from csv file:\n",
      "                                                hash  label     family  \\\n",
      "0  00002d74a9faa53f5199c910b652ef09d3a7f6bd42b693...      1  GinMaster   \n",
      "1  000068216bdb459df847bfdd67dd11069c3c50166db1ea...      0     benign   \n",
      "2  0000764713b286cfe7e8e76c7038c92312977712d9c5a8...      1     Opfake   \n",
      "3  0000962c2c34de1ca0c329b18be7847459da2d9d14b6b2...      0     benign   \n",
      "4  000167f1ff061ea91440c40659c11c2af160342fd2e493...      0     benign   \n",
      "\n",
      "                                      vector  \n",
      "0  [1 1 1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0]  \n",
      "1  [1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]  \n",
      "2  [1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0]  \n",
      "3  [1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]  \n",
      "4  [1 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]  \n",
      "\n",
      "Keys of the loaded dataset:\n",
      "Index(['hash', 'label', 'family', 'vector'], dtype='object')\n",
      "\n",
      "First 5 samples in the dataset:\n",
      "Sample 0: 00002d74a9faa53f5199c910b652ef09d3a7f6bd42b693755a233635c3ffb0f4\n",
      "\t['1', '1', '1', '1', '1', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 1, GinMaster\n",
      "Sample 1: 000068216bdb459df847bfdd67dd11069c3c50166db1ea8772cdc9250d948bcf\n",
      "\t['1', '0', '0', '1', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 0, benign\n",
      "Sample 2: 0000764713b286cfe7e8e76c7038c92312977712d9c5a86d504be54f3c1d025a\n",
      "\t['1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '0', '0'], 1, Opfake\n",
      "Sample 3: 0000962c2c34de1ca0c329b18be7847459da2d9d14b6b23a21cbc6427522403c\n",
      "\t['1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 0, benign\n",
      "Sample 4: 000167f1ff061ea91440c40659c11c2af160342fd2e493d609e4996b8820e78f\n",
      "\t['1', '1', '0', '1', '1', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 0, benign\n"
     ]
    }
   ],
   "source": [
    "# Import pandas libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the csv file\n",
    "def load_dataset_from_csv(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "# Load the dataset from the csv file\n",
    "loaded_dataset = load_dataset_from_csv('vectorized_dataset.csv')\n",
    "print(\"\\nLoaded dataset from csv file:\")\n",
    "print(loaded_dataset.head())\n",
    "\n",
    "# Print keys of the loaded dataset\n",
    "print(\"\\nKeys of the loaded dataset:\")\n",
    "print(loaded_dataset.keys())\n",
    "\n",
    "# Convert all columns to numpy arrays\n",
    "dataset_hashes = loaded_dataset['hash'].tolist()\n",
    "dataset_labels = loaded_dataset['label'].tolist()\n",
    "dataset_families = loaded_dataset['family'].tolist()\n",
    "\n",
    "# Process each vector in the dataset by removing the brackets\n",
    "dataset_vectors = []\n",
    "for vector in loaded_dataset['vector']:\n",
    "    vector = vector.strip('[]').split(' ')\n",
    "    dataset_vectors.append(vector)\n",
    "dataset_vectors = dataset_vectors\n",
    "\n",
    "# Print the first 5 samples in the dataset along with their hashes and labels\n",
    "print(\"\\nFirst 5 samples in the dataset:\")\n",
    "for i in range(5):\n",
    "    print(f\"Sample {i}: {dataset_hashes[i]}\")\n",
    "    print(f\"\\t{dataset_vectors[i]}, {dataset_labels[i]}, {dataset_families[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ChatGPT was used to help convert Numpy SVM to PyTorch SVM using automatic optimizer\"\"\"\n",
    "\n",
    "import torch\n",
    "\n",
    "class SVM:\n",
    "    def __init__(self, epochs=100, learning_rate=0.001):\n",
    "        # Set learning rate and number of epochs/iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "        # Initiate weights and biases to None, assigned based on the size of the first training point\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def predict(self, samples):\n",
    "        # Compute the score/prediction by finding the dot product between the data points and the weights, subtracting the bias\n",
    "        prediction = torch.matmul(samples, self.weights) - self.bias\n",
    "        # Use sign to set the output as 1 if score > 0, -1 if score < 0, or 0\n",
    "        return torch.sign(prediction)\n",
    "    \n",
    "    def fit(self, samples, raw_labels, regularization_term):\n",
    "        # Convert samples and labels to PyTorch tensors\n",
    "        samples = torch.tensor(samples, dtype=torch.float32)\n",
    "        raw_labels = torch.tensor(raw_labels, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "        # Update labels from (0 or 1) to (-1 or 1)\n",
    "        labels = torch.where(raw_labels == 0, -1, 1)\n",
    "\n",
    "        # Get the number of samples and number of features per sample\n",
    "        num_samples, num_features = samples.shape\n",
    "\n",
    "        # Initialize n weights to 0, where n is the number of features\n",
    "        # requires_grad set to True to allow automatic tuning by PyTorch optimizer\n",
    "        self.weights = torch.zeros((num_features, 1), dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "        # Set the initial bias to 0\n",
    "        # requires_grad set to True to allow automatic tuning by PyTorch optimizer\n",
    "        self.bias = torch.zeros(1, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "        # Specify Stocastic Gradient Descent as the optimizer\n",
    "        optimizer = torch.optim.SGD([self.weights, self.bias], lr=self.lr)\n",
    "\n",
    "        # Training function\n",
    "        for epoch_index in range(self.epochs):\n",
    "            # Reset gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Predict the score of the sample (same as predict function w/o function call overhead)\n",
    "            prediction = torch.matmul(samples, self.weights) - self.bias\n",
    "\n",
    "            # Compute the margin by applying the labels to the corresponding predictions\n",
    "            margin = prediction * labels\n",
    "\n",
    "            # Compute the average hinge loss\n",
    "            hinge_loss = torch.mean(torch.clamp(1 - margin, min=0))\n",
    "\n",
    "            # Add regularization to the cost function\n",
    "            reg_cost = regularization_term * torch.norm(self.weights, p=2) / 2\n",
    "\n",
    "            # Calculate total loss\n",
    "            loss = hinge_loss + reg_cost\n",
    "\n",
    "            # Use PyTorch to automatically compute gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
