{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded dataset from csv file:\n",
      "                                                hash  label     family  \\\n",
      "0  00002d74a9faa53f5199c910b652ef09d3a7f6bd42b693...      1  GinMaster   \n",
      "1  000068216bdb459df847bfdd67dd11069c3c50166db1ea...      0     benign   \n",
      "2  0000764713b286cfe7e8e76c7038c92312977712d9c5a8...      1     Opfake   \n",
      "3  0000962c2c34de1ca0c329b18be7847459da2d9d14b6b2...      0     benign   \n",
      "4  000167f1ff061ea91440c40659c11c2af160342fd2e493...      0     benign   \n",
      "\n",
      "                                              vector  \n",
      "0  [1 1 1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0...  \n",
      "1  [1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...  \n",
      "2  [1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0...  \n",
      "3  [1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0...  \n",
      "4  [1 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0...  \n",
      "\n",
      "Keys of the loaded dataset:\n",
      "Index(['hash', 'label', 'family', 'vector'], dtype='object')\n",
      "\n",
      "First 5 samples in the dataset:\n",
      "Sample 0: 00002d74a9faa53f5199c910b652ef09d3a7f6bd42b693755a233635c3ffb0f4\n",
      "\t[1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0], 1, GinMaster\n",
      "Sample 1: 000068216bdb459df847bfdd67dd11069c3c50166db1ea8772cdc9250d948bcf\n",
      "\t[1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 0, benign\n",
      "Sample 2: 0000764713b286cfe7e8e76c7038c92312977712d9c5a86d504be54f3c1d025a\n",
      "\t[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], 1, Opfake\n",
      "Sample 3: 0000962c2c34de1ca0c329b18be7847459da2d9d14b6b23a21cbc6427522403c\n",
      "\t[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 0, benign\n",
      "Sample 4: 000167f1ff061ea91440c40659c11c2af160342fd2e493d609e4996b8820e78f\n",
      "\t[1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 0, benign\n"
     ]
    }
   ],
   "source": [
    "# Import pandas libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the csv file\n",
    "def load_dataset_from_csv(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "# Load the dataset from the csv file\n",
    "loaded_dataset = load_dataset_from_csv('vectorized_dataset.csv')\n",
    "print(\"\\nLoaded dataset from csv file:\")\n",
    "print(loaded_dataset.head())\n",
    "\n",
    "# Print keys of the loaded dataset\n",
    "print(\"\\nKeys of the loaded dataset:\")\n",
    "print(loaded_dataset.keys())\n",
    "\n",
    "# Convert all columns to numpy arrays\n",
    "dataset_hashes = loaded_dataset['hash'].tolist()\n",
    "dataset_labels = loaded_dataset['label'].tolist()\n",
    "dataset_families = loaded_dataset['family'].tolist()\n",
    "\n",
    "# Process each vector in the dataset by removing the brackets\n",
    "dataset_vectors = []\n",
    "for vector in loaded_dataset['vector']:\n",
    "    vector = vector.strip('[]').split(' ')\n",
    "    # Typecast the vector of strings to int\n",
    "    vector = [int(i) for i in vector]\n",
    "    dataset_vectors.append(vector)\n",
    "dataset_vectors = dataset_vectors\n",
    "\n",
    "# Print the first 5 samples in the dataset along with their hashes and labels\n",
    "print(\"\\nFirst 5 samples in the dataset:\")\n",
    "for i in range(5):\n",
    "    print(f\"Sample {i}: {dataset_hashes[i]}\")\n",
    "    print(f\"\\t{dataset_vectors[i]}, {dataset_labels[i]}, {dataset_families[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of families in the dataset: 180\n",
      "\n",
      "Family counts in the dataset:\n",
      "benign: 123453\n",
      "FakeInstaller: 925\n",
      "DroidKungFu: 667\n",
      "Plankton: 625\n",
      "Opfake: 613\n",
      "GinMaster: 339\n",
      "BaseBridge: 330\n",
      "Iconosys: 152\n",
      "Kmin: 147\n",
      "FakeDoc: 132\n",
      "Geinimi: 92\n",
      "Adrd: 91\n",
      "DroidDream: 81\n",
      "ExploitLinuxLotoor: 70\n",
      "Glodream: 69\n",
      "MobileTx: 69\n",
      "FakeRun: 61\n",
      "SendPay: 59\n",
      "Gappusin: 58\n",
      "Imlog: 43\n",
      "SMSreg: 41\n",
      "Yzhc: 37\n",
      "Jifake: 29\n",
      "Hamob: 28\n",
      "Boxer: 27\n",
      "Fakelogo: 19\n",
      "Penetho: 19\n",
      "Nyleaker: 18\n",
      "Xsider: 18\n",
      "FakePlayer: 17\n",
      "Dougalek: 17\n",
      "Fatakr: 17\n",
      "Vdloader: 16\n",
      "FoCobers: 15\n",
      "Stealer: 14\n",
      "SerBG: 14\n",
      "Typstu: 14\n",
      "Mobilespy: 14\n",
      "Steek: 14\n",
      "Zitmo: 14\n",
      "Nandrobox: 13\n",
      "TrojanSMS.Hippo: 13\n",
      "Fakengry: 13\n",
      "SpyHasb: 13\n",
      "Copycat: 12\n",
      "FakeTimer: 12\n",
      "Nickspy: 12\n",
      "Placms: 12\n",
      "Cosha: 11\n",
      "DroidSheep: 11\n",
      "Spitmo: 11\n",
      "Biige: 10\n",
      "AccuTrack: 10\n",
      "SMSZombie: 10\n",
      "Raden: 10\n",
      "Kiser: 9\n",
      "Stiniter: 9\n",
      "Zsone: 8\n",
      "Mobinauten: 8\n",
      "Spyset: 8\n",
      "Coogos: 8\n",
      "BeanBot: 8\n",
      "Sakezon: 8\n",
      "RootSmart: 7\n",
      "Gapev: 7\n",
      "Ceshark: 7\n",
      "Gamex: 7\n",
      "Mania: 6\n",
      "Lemon: 6\n",
      "Ksapp: 6\n",
      "SeaWeth: 6\n",
      "Kidlogger: 6\n",
      "Fjcon: 6\n",
      "QPlus: 6\n",
      "Trackplus: 6\n",
      "Aks: 5\n",
      "FarMap: 5\n",
      "TrojanSMS.Denofow: 5\n",
      "Stealthcell: 5\n",
      "FaceNiff: 5\n",
      "SpyPhone: 5\n",
      "Luckycat: 5\n",
      "Vidro: 5\n",
      "Gonca: 5\n",
      "DroidRooter: 4\n",
      "PdaSpy: 4\n",
      "EICAR-Test-File: 4\n",
      "Nisev: 4\n",
      "Replicator: 4\n",
      "RediAssi: 3\n",
      "FakeFlash: 3\n",
      "GGtrack: 3\n",
      "Tapsnake: 3\n",
      "Generic: 3\n",
      "SmsWatcher: 3\n",
      "TigerBot: 3\n",
      "Hispo: 3\n",
      "SpyMob: 3\n",
      "LifeMon: 3\n",
      "Spyoo: 3\n",
      "Moghava: 3\n",
      "Fsm: 3\n",
      "Gmuse: 3\n",
      "FinSpy: 3\n",
      "Adsms: 3\n",
      "Fidall: 3\n",
      "Rooter: 3\n",
      "GPSpy: 3\n",
      "SpyBubble: 3\n",
      "Proreso: 2\n",
      "Foncy: 2\n",
      "SmForw: 2\n",
      "YcChar: 2\n",
      "Koomer: 2\n",
      "Fauxcopy: 2\n",
      "Dialer: 2\n",
      "Loozfon: 2\n",
      "Tesbo: 2\n",
      "SheriDroid: 2\n",
      "Ackposts: 2\n",
      "CgFinder: 2\n",
      "Anti: 2\n",
      "Dogowar: 2\n",
      "Dabom: 2\n",
      "CrWind: 2\n",
      "CellSpy: 2\n",
      "NickyRCP: 2\n",
      "Antares: 2\n",
      "TheftAware: 2\n",
      "JSmsHider: 2\n",
      "Pirates: 2\n",
      "Saiva: 2\n",
      "Flexispy: 2\n",
      "TrojanSMS.Boxer.AQ: 1\n",
      "SuBatt: 1\n",
      "Anudow: 1\n",
      "SMSSend: 1\n",
      "Fujacks: 1\n",
      "Maxit: 1\n",
      "MMarketPay: 1\n",
      "Gasms: 1\n",
      "Spy.ImLog: 1\n",
      "Arspam: 1\n",
      "Booster: 1\n",
      "SMSBomber: 1\n",
      "SmsSpy: 1\n",
      "Acnetdoor: 1\n",
      "TrojanSMS.Stealer: 1\n",
      "Lypro: 1\n",
      "Spy.GoneSixty: 1\n",
      "Fakeview: 1\n",
      "Mobsquz: 1\n",
      "Sdisp: 1\n",
      "GlodEagl: 1\n",
      "RuFraud: 1\n",
      "Sonus: 1\n",
      "Qicsom: 1\n",
      "FakeNefix: 1\n",
      "Ansca: 1\n",
      "Ssmsp: 1\n",
      "Exploit.RageCage: 1\n",
      "MTracker: 1\n",
      "JS/Exploit-DynSrc: 1\n",
      "Loicdos: 1\n",
      "RATC: 1\n",
      "UpdtKiller: 1\n",
      "SafeKidZone: 1\n",
      "Maistealer: 1\n",
      "Updtbot: 1\n",
      "CellShark: 1\n",
      "EWalls: 1\n",
      "Netisend: 1\n",
      "Cawitt: 1\n",
      "Whapsni: 1\n",
      "Faceniff: 1\n",
      "PJApps: 1\n",
      "Pirater: 1\n",
      "Bgserv: 1\n",
      "Smspacem: 1\n",
      "Bosm: 1\n"
     ]
    }
   ],
   "source": [
    "# Print the number of families in the dataset\n",
    "print(\"\\nNumber of families in the dataset:\", len(set(dataset_families)))\n",
    "\n",
    "# Print each family in the dataset and its count, sorted by count\n",
    "family_counts = pd.Series(dataset_families).value_counts()\n",
    "print(\"\\nFamily counts in the dataset:\")\n",
    "for family, count in family_counts.items():\n",
    "    print(f\"{family}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of training sets created: 55\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Generate a one-vs-all training set for each family in the dataset with more than n occurrences\n",
    "# Set to 0 to create a dataset for all families\n",
    "min_occurrences = 10\n",
    "\n",
    "# Create a dictionary to store the training sets for each family\n",
    "training_sets_samples = {}\n",
    "training_sets_labels = {}\n",
    "\n",
    "# Iterate through each family and create a one-vs-all training set\n",
    "for family in family_counts.index:\n",
    "    if family_counts[family] >= min_occurrences:\n",
    "        training_set_samples = []\n",
    "        training_set_labels = []\n",
    "        # Append malware samples for the current family\n",
    "        malware_indexes = [i for i in range(len(dataset_families)) if dataset_families[i] == family]\n",
    "        index = 0\n",
    "        # Create a balanced dataset with 50,000 malware samples and 50,000 benign samples\n",
    "        while len(training_set_samples) < 50000:\n",
    "            training_set_samples.append(dataset_vectors[malware_indexes[index]])\n",
    "            training_set_labels.append(1)\n",
    "            index += 1\n",
    "            if index >= len(malware_indexes):\n",
    "                index = 0\n",
    "        # Append benign samples for the current family\n",
    "        benign_indexes = [i for i in range(len(dataset_families)) if dataset_families[i] != family]\n",
    "        index = 0\n",
    "        while len(training_set_samples) < 100000:\n",
    "            training_set_samples.append(dataset_vectors[benign_indexes[index]])\n",
    "            training_set_labels.append(0)\n",
    "            index += 1\n",
    "            if index >= len(benign_indexes):\n",
    "                index = 0\n",
    "        training_sets_samples[family] = training_set_samples\n",
    "        training_sets_labels[family] = training_set_labels\n",
    "\n",
    "# Print the number of training sets created\n",
    "print(\"\\nNumber of training sets created:\", len(training_sets_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of malware and benign samples in each training set:\n",
      "benign: 50000 malware samples, 50000 benign samples\n",
      "FakeInstaller: 50000 malware samples, 50000 benign samples\n",
      "DroidKungFu: 50000 malware samples, 50000 benign samples\n",
      "Plankton: 50000 malware samples, 50000 benign samples\n",
      "Opfake: 50000 malware samples, 50000 benign samples\n",
      "GinMaster: 50000 malware samples, 50000 benign samples\n",
      "BaseBridge: 50000 malware samples, 50000 benign samples\n",
      "Iconosys: 50000 malware samples, 50000 benign samples\n",
      "Kmin: 50000 malware samples, 50000 benign samples\n",
      "FakeDoc: 50000 malware samples, 50000 benign samples\n",
      "Geinimi: 50000 malware samples, 50000 benign samples\n",
      "Adrd: 50000 malware samples, 50000 benign samples\n",
      "DroidDream: 50000 malware samples, 50000 benign samples\n",
      "ExploitLinuxLotoor: 50000 malware samples, 50000 benign samples\n",
      "Glodream: 50000 malware samples, 50000 benign samples\n",
      "MobileTx: 50000 malware samples, 50000 benign samples\n",
      "FakeRun: 50000 malware samples, 50000 benign samples\n",
      "SendPay: 50000 malware samples, 50000 benign samples\n",
      "Gappusin: 50000 malware samples, 50000 benign samples\n",
      "Imlog: 50000 malware samples, 50000 benign samples\n",
      "SMSreg: 50000 malware samples, 50000 benign samples\n",
      "Yzhc: 50000 malware samples, 50000 benign samples\n",
      "Jifake: 50000 malware samples, 50000 benign samples\n",
      "Hamob: 50000 malware samples, 50000 benign samples\n",
      "Boxer: 50000 malware samples, 50000 benign samples\n",
      "Fakelogo: 50000 malware samples, 50000 benign samples\n",
      "Penetho: 50000 malware samples, 50000 benign samples\n",
      "Nyleaker: 50000 malware samples, 50000 benign samples\n",
      "Xsider: 50000 malware samples, 50000 benign samples\n",
      "FakePlayer: 50000 malware samples, 50000 benign samples\n",
      "Dougalek: 50000 malware samples, 50000 benign samples\n",
      "Fatakr: 50000 malware samples, 50000 benign samples\n",
      "Vdloader: 50000 malware samples, 50000 benign samples\n",
      "FoCobers: 50000 malware samples, 50000 benign samples\n",
      "Stealer: 50000 malware samples, 50000 benign samples\n",
      "SerBG: 50000 malware samples, 50000 benign samples\n",
      "Typstu: 50000 malware samples, 50000 benign samples\n",
      "Mobilespy: 50000 malware samples, 50000 benign samples\n",
      "Steek: 50000 malware samples, 50000 benign samples\n",
      "Zitmo: 50000 malware samples, 50000 benign samples\n",
      "Nandrobox: 50000 malware samples, 50000 benign samples\n",
      "TrojanSMS.Hippo: 50000 malware samples, 50000 benign samples\n",
      "Fakengry: 50000 malware samples, 50000 benign samples\n",
      "SpyHasb: 50000 malware samples, 50000 benign samples\n",
      "Copycat: 50000 malware samples, 50000 benign samples\n",
      "FakeTimer: 50000 malware samples, 50000 benign samples\n",
      "Nickspy: 50000 malware samples, 50000 benign samples\n",
      "Placms: 50000 malware samples, 50000 benign samples\n",
      "Cosha: 50000 malware samples, 50000 benign samples\n",
      "DroidSheep: 50000 malware samples, 50000 benign samples\n",
      "Spitmo: 50000 malware samples, 50000 benign samples\n",
      "Biige: 50000 malware samples, 50000 benign samples\n",
      "AccuTrack: 50000 malware samples, 50000 benign samples\n",
      "SMSZombie: 50000 malware samples, 50000 benign samples\n",
      "Raden: 50000 malware samples, 50000 benign samples\n"
     ]
    }
   ],
   "source": [
    "# Print the number of malware and benign samples in each training set\n",
    "print(\"\\nNumber of malware and benign samples in each training set:\")\n",
    "for family, labels in training_sets_labels.items():\n",
    "    print(f\"{family}: {labels.count(1)} malware samples, {labels.count(0)} benign samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 samples of the training set for family 'FakeInstaller':\n",
      "Sample 0: 00002d74a9faa53f5199c910b652ef09d3a7f6bd42b693755a233635c3ffb0f4\n",
      "\t[1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 1\n",
      "Sample 1: 000068216bdb459df847bfdd67dd11069c3c50166db1ea8772cdc9250d948bcf\n",
      "\t[1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 1\n",
      "Sample 2: 0000764713b286cfe7e8e76c7038c92312977712d9c5a86d504be54f3c1d025a\n",
      "\t[1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 1\n",
      "Sample 3: 0000962c2c34de1ca0c329b18be7847459da2d9d14b6b23a21cbc6427522403c\n",
      "\t[1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 1\n",
      "Sample 4: 000167f1ff061ea91440c40659c11c2af160342fd2e493d609e4996b8820e78f\n",
      "\t[1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 1\n"
     ]
    }
   ],
   "source": [
    "# Print the first 5 samples of the training set for the family at index idx\n",
    "idx = 1\n",
    "family = family_counts.index[idx]\n",
    "print(f\"\\nFirst 5 samples of the training set for family '{family}':\")\n",
    "for i in range(5):\n",
    "    print(f\"Sample {i}: {dataset_hashes[i]}\")\n",
    "    print(f\"\\t{training_sets_samples[family][i]}, {training_sets_labels[family][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ChatGPT was used to help convert Numpy SVM to PyTorch SVM using automatic optimizer\"\"\"\n",
    "\n",
    "import torch\n",
    "\n",
    "class SVM:\n",
    "    def __init__(self, epochs=1000, learning_rate=0.001):\n",
    "        # Set learning rate and number of epochs/iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "        # Initiate weights and biases to None, assigned based on the size of the first training point\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "    \n",
    "    def fit(self, samples, raw_labels, regularization_term):\n",
    "        # Convert samples and labels to PyTorch tensors\n",
    "        samples = torch.tensor(samples, dtype=torch.float32)\n",
    "        raw_labels = torch.tensor(raw_labels, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "        # Update labels from (0 or 1) to (-1 or 1) for hinge loss calculation\n",
    "        labels = torch.where(raw_labels == 1, torch.tensor(1.0, dtype=torch.float32), torch.tensor(-1.0, dtype=torch.float32))\n",
    "\n",
    "        # Get the number of samples and number of features per sample\n",
    "        num_samples, num_features = samples.shape\n",
    "\n",
    "        # Initialize n weights to 0, where n is the number of features\n",
    "        # requires_grad set to True to allow automatic tuning by PyTorch optimizer\n",
    "        self.weights = torch.zeros((num_features, 1), dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "        # Set the initial bias to 0 (tensor of size 1)\n",
    "        # requires_grad set to True to allow automatic tuning by PyTorch optimizer\n",
    "        self.bias = torch.zeros(1, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "        # Specify Stocastic Gradient Descent as the optimizer\n",
    "        optimizer = torch.optim.SGD([self.weights, self.bias], lr=self.learning_rate)\n",
    "\n",
    "        # Training function\n",
    "        for epoch_index in range(self.epochs):\n",
    "            # Reset gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Predict the score of the sample (same as predict function w/o function call overhead)\n",
    "            prediction = torch.matmul(samples, self.weights) - self.bias\n",
    "\n",
    "            # Compute the margin by applying the labels to the corresponding predictions\n",
    "            margin = prediction * labels\n",
    "\n",
    "            # Compute the average hinge loss\n",
    "            hinge_loss = torch.mean(torch.clamp(1 - margin, min=0))\n",
    "\n",
    "            # Add regularization to the cost function\n",
    "            reg_cost = regularization_term * torch.norm(self.weights, p=2) / 2\n",
    "\n",
    "            # Calculate total loss\n",
    "            loss = hinge_loss + reg_cost\n",
    "\n",
    "            # Use PyTorch to automatically compute gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "        \n",
    "    def predict(self, samples):\n",
    "        # Compute the score/prediction by finding the dot product between the data points and the weights, including the bias\n",
    "        return torch.sigmoid(torch.matmul(samples, self.weights) + self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trained SVM model:\n",
      "Bias: tensor([0.9808], requires_grad=True)\n",
      "\n",
      "First 5 samples of the training set for family 'Gappusin' where the label is 1:\n",
      "Sample 0: 00002d74a9faa53f5199c910b652ef09d3a7f6bd42b693755a233635c3ffb0f4\n",
      "\t[1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 1\n",
      "\tPrediction: tensor([0.9508], grad_fn=<SigmoidBackward0>)\n",
      "Sample 1: 000068216bdb459df847bfdd67dd11069c3c50166db1ea8772cdc9250d948bcf\n",
      "\t[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 1\n",
      "\tPrediction: tensor([0.9669], grad_fn=<SigmoidBackward0>)\n",
      "Sample 2: 0000764713b286cfe7e8e76c7038c92312977712d9c5a86d504be54f3c1d025a\n",
      "\t[1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 1\n",
      "\tPrediction: tensor([0.9315], grad_fn=<SigmoidBackward0>)\n",
      "Sample 3: 0000962c2c34de1ca0c329b18be7847459da2d9d14b6b23a21cbc6427522403c\n",
      "\t[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], 1\n",
      "\tPrediction: tensor([0.8815], grad_fn=<SigmoidBackward0>)\n",
      "Sample 4: 000167f1ff061ea91440c40659c11c2af160342fd2e493d609e4996b8820e78f\n",
      "\t[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 1\n",
      "\tPrediction: tensor([0.9673], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "First 5 samples of the training set for family 'Gappusin' where the label is 0:\n",
      "Sample 50000: 63120521eae8dc4a1cd0df68b1a8df1c0b01d58522e874dd10a0fec2ce884f39\n",
      "\t[1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0], 0\n",
      "\tPrediction: tensor([0.9425], grad_fn=<SigmoidBackward0>)\n",
      "Sample 50001: 6312646f4c90c4578397362c06667d26efaec38eb2a55e0378879d614779b197\n",
      "\t[1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 0\n",
      "\tPrediction: tensor([0.8339], grad_fn=<SigmoidBackward0>)\n",
      "Sample 50002: 631387bd6baa9d1932c52fb278e03690376ef03d1ef2a56dd40e946423ba4f07\n",
      "\t[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], 0\n",
      "\tPrediction: tensor([0.7648], grad_fn=<SigmoidBackward0>)\n",
      "Sample 50003: 631476c68f3867bd771765d0868f38fbdab5bfda1d9c05ed83b23b8ee8e4abab\n",
      "\t[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 0\n",
      "\tPrediction: tensor([0.3991], grad_fn=<SigmoidBackward0>)\n",
      "Sample 50004: 6314ae717606dd9a69a1363877472b6f0332b1a87656838becba87d95b0c4b6c\n",
      "\t[1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 0\n",
      "\tPrediction: tensor([0.7805], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "Accuracy of the model on the training set for family 'Gappusin': 0.66196\n"
     ]
    }
   ],
   "source": [
    "# Create an SVM object\n",
    "svm = SVM(epochs=5000, learning_rate=0.005)\n",
    "\n",
    "# Train the SVM model using the training set for the family at index idx\n",
    "# The training set at idx 0 is benign\n",
    "idx = 18\n",
    "family = family_counts.index[idx]\n",
    "\n",
    "# Train the single class SVM model on the training set\n",
    "svm.fit(training_sets_samples[family], training_sets_labels[family], regularization_term=0)\n",
    "\n",
    "# Print the weights and bias of the trained SVM model\n",
    "print(\"\\nTrained SVM model:\")\n",
    "# print(f\"Weights: {svm.weights}\")\n",
    "print(f\"Bias: {svm.bias}\")\n",
    "\n",
    "# Print the first 5 samples of the training set for the family where the label is 1\n",
    "print(f\"\\nFirst 5 samples of the training set for family '{family}' where the label is 1:\")\n",
    "count = 0\n",
    "for i in range(len(training_sets_labels[family])):\n",
    "    if training_sets_labels[family][i] == 1:\n",
    "        print(f\"Sample {i}: {dataset_hashes[i]}\")\n",
    "        print(f\"\\t{training_sets_samples[family][i]}, {training_sets_labels[family][i]}\")\n",
    "        print(f\"\\tPrediction: {svm.predict(torch.tensor(training_sets_samples[family][i], dtype=torch.float32))}\")\n",
    "        count += 1\n",
    "        if count == 5:\n",
    "            break\n",
    "\n",
    "# Print the first 5 samples of the training set for the family where the label is 0\n",
    "print(f\"\\nFirst 5 samples of the training set for family '{family}' where the label is 0:\")\n",
    "count = 0\n",
    "for i in range(len(training_sets_labels[family])):\n",
    "    if training_sets_labels[family][i] == 0:\n",
    "        print(f\"Sample {i}: {dataset_hashes[i]}\")\n",
    "        print(f\"\\t{training_sets_samples[family][i]}, {training_sets_labels[family][i]}\")\n",
    "        print(f\"\\tPrediction: {svm.predict(torch.tensor(training_sets_samples[family][i], dtype=torch.float32))}\")\n",
    "        count += 1\n",
    "        if count == 5:\n",
    "            break\n",
    "\n",
    "# Get the accuracy of the model on the training set\n",
    "correct_predictions = 0\n",
    "for i in range(len(training_sets_labels[family])):\n",
    "    prediction = svm.predict(torch.tensor(training_sets_samples[family][i], dtype=torch.float32))\n",
    "    if (prediction >= 0.5 and training_sets_labels[family][i] == 1) or (prediction < 0.5 and training_sets_labels[family][i] == 0):\n",
    "        correct_predictions += 1\n",
    "accuracy = correct_predictions / len(training_sets_labels[family])\n",
    "print(f\"\\nAccuracy of the model on the training set for family '{family}': {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ensemble classifier which initializes multiple one vs all SVM classifiers, including one for benign samples\n",
    "# Each SVM classifier makes a prediction on the sample data and outputs a score\n",
    "# The classifier with the highest score classifies the sample\n",
    "\n",
    "class Ensemble_SVM:\n",
    "    def __init__(self, epochs=1000, learning_rate=0.001):\n",
    "        # Store the number of epochs and learning rate\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        # Set the number of models in the ensemble\n",
    "        self.num_models = None\n",
    "        # Initialize a list to store the models and a list for the corresponding family names\n",
    "        self.models = []\n",
    "        self.model_families = []\n",
    "    \n",
    "    def fit(self, families, sample_sets, label_sets, regularization_term=0.5):\n",
    "        # Get the number of models\n",
    "        self.num_models = len(families)\n",
    "        for index in range(len(families)):\n",
    "            self.model_families.append(families[index])\n",
    "            # Create an SVM model for each family and train it\n",
    "            model = SVM(epochs=self.epochs, learning_rate=self.learning_rate)\n",
    "            model.fit(sample_sets[index], label_sets[index], regularization_term)\n",
    "            self.models.append(model)\n",
    "    \n",
    "    def predict(self, samples):\n",
    "        # Predict the class of the sample using voting (highest score)\n",
    "        predictions = []\n",
    "        for model in self.models:\n",
    "            predictions.append(model.predict(samples))\n",
    "        # Get the index of the model with the highest prediction\n",
    "        max_index = predictions.index(max(predictions))\n",
    "        return self.model_families[max_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 families used in the ensemble model:\n",
      "['benign', 'FakeInstaller', 'DroidKungFu', 'Plankton', 'Opfake', 'GinMaster', 'BaseBridge', 'Iconosys', 'Kmin', 'FakeDoc', 'Geinimi', 'Adrd', 'DroidDream', 'ExploitLinuxLotoor', 'Glodream', 'MobileTx', 'FakeRun', 'SendPay', 'Gappusin', 'Imlog']\n"
     ]
    }
   ],
   "source": [
    "# Train an emsemble SVM model using the top 20 families with the most occurrences\n",
    "top_families = family_counts[:20].index.tolist()\n",
    "top_sample_sets = []\n",
    "top_label_sets = []\n",
    "for family in top_families:\n",
    "    top_sample_sets.append(training_sets_samples[family])\n",
    "    top_label_sets.append(training_sets_labels[family])\n",
    "\n",
    "ensemble_svm = Ensemble_SVM(epochs=2000, learning_rate=0.005)\n",
    "ensemble_svm.fit(top_families, top_sample_sets, top_label_sets, regularization_term=0)\n",
    "\n",
    "# Print the top 20 families used in the ensemble model\n",
    "print(\"\\nTop 20 families used in the ensemble model:\")\n",
    "print(top_families)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifying the first 5 samples in the dataset using the ensemble model:\n",
      "Sample 0: 00002d74a9faa53f5199c910b652ef09d3a7f6bd42b693755a233635c3ffb0f4\n",
      "\tFamily: GinMaster, Actual Family: GinMaster\n",
      "Sample 1: 000068216bdb459df847bfdd67dd11069c3c50166db1ea8772cdc9250d948bcf\n",
      "\tFamily: Adrd, Actual Family: benign\n",
      "Sample 2: 0000764713b286cfe7e8e76c7038c92312977712d9c5a86d504be54f3c1d025a\n",
      "\tFamily: Adrd, Actual Family: Opfake\n",
      "Sample 3: 0000962c2c34de1ca0c329b18be7847459da2d9d14b6b23a21cbc6427522403c\n",
      "\tFamily: benign, Actual Family: benign\n",
      "Sample 4: 000167f1ff061ea91440c40659c11c2af160342fd2e493d609e4996b8820e78f\n",
      "\tFamily: Imlog, Actual Family: benign\n",
      "Sample 5: 00017ed2c044caf7b1047184673ec3e11ab10ac0e64fb7e7bccaca0deb13198a\n",
      "\tFamily: Plankton, Actual Family: benign\n",
      "Sample 6: 000189f3a91b1c19f15e2838995f80d6bb40d74aa8135f6d3e4fdbb80a0bdee7\n",
      "\tFamily: Adrd, Actual Family: benign\n",
      "Sample 7: 0003043c7e2af5e07a2638fbf2391802b0c9ff1926e5d04d06df06992147a325\n",
      "\tFamily: Plankton, Actual Family: benign\n",
      "Sample 8: 00032ac5f91c29399f9727a082b6e1aa0a761f479a16ebd039b5916b76326701\n",
      "\tFamily: Gappusin, Actual Family: benign\n",
      "Sample 9: 00039901d26fa9121f32762d8b0e67df7cfbcbb53e0fe3da7fb1298dab84c816\n",
      "\tFamily: benign, Actual Family: benign\n",
      "Sample 10: 00048d3843606d5431eee520e0fbea8b9a5746b371dce09cce9e307a67669059\n",
      "\tFamily: SendPay, Actual Family: benign\n",
      "Sample 11: 000569476720338e9e6083ebd637c5f583624553b1bfb0ba3d0a182a8ce64692\n",
      "\tFamily: GinMaster, Actual Family: benign\n",
      "Sample 12: 0005b212ef1de80cc95e2a6d5b7fe5eec63138a800ae9a4ccd9bb2b552574299\n",
      "\tFamily: Adrd, Actual Family: benign\n",
      "Sample 13: 00064c13f3f247c4b523149b3bb089e09178e1e30e87fd12592ec33de4fffbd0\n",
      "\tFamily: SendPay, Actual Family: benign\n",
      "Sample 14: 0006af83d80f25f31778831c2d1682f5c6e5d28e03e18e78d83943aedd3a1ee5\n",
      "\tFamily: DroidKungFu, Actual Family: benign\n",
      "Sample 15: 0006b6fe38b01798827b8eb25ac61ff13ee109ab535d1628b8e5b448155ff2d1\n",
      "\tFamily: benign, Actual Family: benign\n",
      "Sample 16: 0006b86410e03fb456474da7deb5ba781df1c05b5fc086c1a849169f85631668\n",
      "\tFamily: Iconosys, Actual Family: benign\n",
      "Sample 17: 0006db2d5f508359f62ce053eb04d0b8aa155726280d7705930e72ce31d1b2de\n",
      "\tFamily: benign, Actual Family: benign\n",
      "Sample 18: 0006efda7fe6a64706b75b5bffb56af46dadec891a9421363c18661bc98f3763\n",
      "\tFamily: FakeRun, Actual Family: benign\n",
      "Sample 19: 000726f1536adf6ab7a0427ab483cad36345853d0943507a4d952e8deb3dacf0\n",
      "\tFamily: SendPay, Actual Family: benign\n",
      "Sample 20: 00083d68250c6089521823d714e25fecf68da2a3e2a39bd4dc100e806eac5cbe\n",
      "\tFamily: benign, Actual Family: benign\n",
      "Sample 21: 00088e191503bbfbd5c56a789a71e8c718e42ea422ec73c760ee2de489e02b2e\n",
      "\tFamily: Adrd, Actual Family: FakeInstaller\n",
      "Sample 22: 0008cd159c49092fb498130f307dc8d3e9894983c1dbf8631ade1b19e27ea011\n",
      "\tFamily: Imlog, Actual Family: benign\n",
      "Sample 23: 000a067df9235aea987cd1e6b7768bcc1053e640b267c5b1f0deefc18be5dbe1\n",
      "\tFamily: Opfake, Actual Family: Boxer\n",
      "Sample 24: 000c720d1f8e3fd2bbf9ea27b56c0485cd81d61f12644f526277bffdae9859f1\n",
      "\tFamily: DroidKungFu, Actual Family: benign\n",
      "Sample 25: 000c9adc69e73a2d2d9d438ed411069739e5e00a5f7166871c954c2f89becf3e\n",
      "\tFamily: Gappusin, Actual Family: benign\n",
      "Sample 26: 000e0948176bdec2b6e19d0f03e23f37910676a9b7e7709954614bac79269c36\n",
      "\tFamily: SendPay, Actual Family: Jifake\n",
      "Sample 27: 000e3bb70a526cf5781c4a5c6a62d050d033158e62468a5c07eab9079e9ca0f8\n",
      "\tFamily: DroidDream, Actual Family: benign\n",
      "Sample 28: 000f395d7e27ff3f76dcbff9902a776fa902bcfd84ca172a769452920b7a3dda\n",
      "\tFamily: benign, Actual Family: benign\n",
      "Sample 29: 000f50ba06ec40b1d9778663b28d1b720e7ebfea5378507c88fc99b1c37b1feb\n",
      "\tFamily: GinMaster, Actual Family: benign\n",
      "Sample 30: 001001e1cecda2d788a49dfe98bd79fa2f1b8dd416461b319c81a598174beee9\n",
      "\tFamily: Gappusin, Actual Family: benign\n",
      "Sample 31: 0011a8145568f47cfaa5f2b7379a5177518222aca4b977508fa81ee4039e4954\n",
      "\tFamily: benign, Actual Family: benign\n",
      "Sample 32: 001294038f94f3b88274c312e53498a3e4f0d2e2c6c6ae9d455f16da5beb0c46\n",
      "\tFamily: benign, Actual Family: benign\n",
      "Sample 33: 00131a88018bf6de509fb99398b1e09269644691fb44b9bf0e4eb6c250af2b23\n",
      "\tFamily: GinMaster, Actual Family: benign\n",
      "Sample 34: 0013639bea9fd564d8a97d104ee0677ef4d44dbdfa4f5b92423c694b58a80585\n",
      "\tFamily: ExploitLinuxLotoor, Actual Family: benign\n",
      "Sample 35: 0013732ee80ab5f84387d7e98f95db710bd93714393a048559f1496108785bf6\n",
      "\tFamily: Adrd, Actual Family: benign\n",
      "Sample 36: 00137ebe6d13e8d23b5487b48093ff2b92e92ae347d5bde5b056f95b246de0c5\n",
      "\tFamily: benign, Actual Family: benign\n",
      "Sample 37: 0013d7d0ac950b6d275eff8f4631924411eca3e78995c88ccd60a2a62ee9f989\n",
      "\tFamily: Adrd, Actual Family: benign\n",
      "Sample 38: 00141bcc792d99140aee026045741cfccbbbefff1a29b45409f2934b479b0948\n",
      "\tFamily: benign, Actual Family: benign\n",
      "Sample 39: 0014ab58103fc5c92827dcb6d034c4bc99ae15bb929acf0f039e9b7ec69bfded\n",
      "\tFamily: FakeRun, Actual Family: benign\n",
      "Sample 40: 001597d07243899e5d2dccdf2095168f8c489e98659ec5d7e234145293359bec\n",
      "\tFamily: Gappusin, Actual Family: benign\n",
      "Sample 41: 0015ae7c27688d45f79170dcea16131ce557912a1a0c5f3b6b0465ee0774a452\n",
      "\tFamily: Gappusin, Actual Family: DroidKungFu\n",
      "Sample 42: 0016593e06f92eb8fb405ff915e177a1f47584a91caddf88529a71ec026f175e\n",
      "\tFamily: benign, Actual Family: benign\n",
      "Sample 43: 00169c38e7f84805a3ed92d8f2c50c10de36711a83ac7fa8597012749b4d7148\n",
      "\tFamily: Gappusin, Actual Family: benign\n",
      "Sample 44: 00171e2275b154cdf351b776c5c5e3e5826c6b65d714d581d9214a982384e361\n",
      "\tFamily: benign, Actual Family: benign\n",
      "Sample 45: 001919f842f8975466506bc5724191f11e9a8803f70bb86dc213b9998a4c6084\n",
      "\tFamily: Imlog, Actual Family: benign\n",
      "Sample 46: 00191d1f2568eeca01c2ee72081feb64ecd00fe5fd78a94f7c1e7d344c07204e\n",
      "\tFamily: benign, Actual Family: benign\n",
      "Sample 47: 0019f7bce733e79892afb4ac3c194f664774af50be53065b0bbf3bd0c249dfec\n",
      "\tFamily: Gappusin, Actual Family: benign\n",
      "Sample 48: 001a6eb58b918aed5dbb4e7629f6b7b98a4868947ddcc6a2218faab97c84877d\n",
      "\tFamily: benign, Actual Family: benign\n",
      "Sample 49: 001c4b54d7d37ecea521f34dd68a607c0b3d3361b6b68f7ede3a12cfd00e1767\n",
      "\tFamily: Plankton, Actual Family: benign\n"
     ]
    }
   ],
   "source": [
    "# Classify the first 5 samples in the dataset using the ensemble model\n",
    "print(\"\\nClassifying the first 5 samples in the dataset using the ensemble model:\")\n",
    "for i in range(50):\n",
    "    family = ensemble_svm.predict(torch.tensor(dataset_vectors[i], dtype=torch.float32))\n",
    "    print(f\"Sample {i}: {dataset_hashes[i]}\")\n",
    "    print(f\"\\tFamily: {family}, Actual Family: {dataset_families[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 samples of the training set for family 'Gappusin' where the label is 1:\n",
      "Sample 0: 00002d74a9faa53f5199c910b652ef09d3a7f6bd42b693755a233635c3ffb0f4\n",
      "\t[1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 1\n",
      "\tPrediction: tensor([0.9186], grad_fn=<SigmoidBackward0>)\n",
      "Sample 1: 000068216bdb459df847bfdd67dd11069c3c50166db1ea8772cdc9250d948bcf\n",
      "\t[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 1\n",
      "\tPrediction: tensor([0.9274], grad_fn=<SigmoidBackward0>)\n",
      "Sample 2: 0000764713b286cfe7e8e76c7038c92312977712d9c5a86d504be54f3c1d025a\n",
      "\t[1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 1\n",
      "\tPrediction: tensor([0.8914], grad_fn=<SigmoidBackward0>)\n",
      "Sample 3: 0000962c2c34de1ca0c329b18be7847459da2d9d14b6b23a21cbc6427522403c\n",
      "\t[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], 1\n",
      "\tPrediction: tensor([0.8213], grad_fn=<SigmoidBackward0>)\n",
      "Sample 4: 000167f1ff061ea91440c40659c11c2af160342fd2e493d609e4996b8820e78f\n",
      "\t[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 1\n",
      "\tPrediction: tensor([0.9346], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "First 5 samples of the training set for family 'Gappusin' where the label is 0:\n",
      "Sample 50000: 63120521eae8dc4a1cd0df68b1a8df1c0b01d58522e874dd10a0fec2ce884f39\n",
      "\t[1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0], 0\n",
      "\tPrediction: tensor([0.9049], grad_fn=<SigmoidBackward0>)\n",
      "Sample 50001: 6312646f4c90c4578397362c06667d26efaec38eb2a55e0378879d614779b197\n",
      "\t[1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 0\n",
      "\tPrediction: tensor([0.7713], grad_fn=<SigmoidBackward0>)\n",
      "Sample 50002: 631387bd6baa9d1932c52fb278e03690376ef03d1ef2a56dd40e946423ba4f07\n",
      "\t[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], 0\n",
      "\tPrediction: tensor([0.7444], grad_fn=<SigmoidBackward0>)\n",
      "Sample 50003: 631476c68f3867bd771765d0868f38fbdab5bfda1d9c05ed83b23b8ee8e4abab\n",
      "\t[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 0\n",
      "\tPrediction: tensor([0.4016], grad_fn=<SigmoidBackward0>)\n",
      "Sample 50004: 6314ae717606dd9a69a1363877472b6f0332b1a87656838becba87d95b0c4b6c\n",
      "\t[1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 0\n",
      "\tPrediction: tensor([0.7240], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "Accuracy of the model on the training set for family 'Gappusin': 0.65923\n"
     ]
    }
   ],
   "source": [
    "index = 18\n",
    "family = ensemble_svm.model_families[index]\n",
    "training_set_samples = top_sample_sets[index]\n",
    "training_set_labels = top_label_sets[index]\n",
    "svm = ensemble_svm.models[index]\n",
    "\n",
    "# Print the first 5 samples of the training set for the family where the label is 1\n",
    "print(f\"\\nFirst 5 samples of the training set for family '{family}' where the label is 1:\")\n",
    "count = 0\n",
    "for i in range(len(training_sets_labels[family])):\n",
    "    if training_sets_labels[family][i] == 1:\n",
    "        print(f\"Sample {i}: {dataset_hashes[i]}\")\n",
    "        print(f\"\\t{training_sets_samples[family][i]}, {training_sets_labels[family][i]}\")\n",
    "        print(f\"\\tPrediction: {svm.predict(torch.tensor(training_sets_samples[family][i], dtype=torch.float32))}\")\n",
    "        count += 1\n",
    "        if count == 5:\n",
    "            break\n",
    "\n",
    "# Print the first 5 samples of the training set for the family where the label is 0\n",
    "print(f\"\\nFirst 5 samples of the training set for family '{family}' where the label is 0:\")\n",
    "count = 0\n",
    "for i in range(len(training_sets_labels[family])):\n",
    "    if training_sets_labels[family][i] == 0:\n",
    "        print(f\"Sample {i}: {dataset_hashes[i]}\")\n",
    "        print(f\"\\t{training_sets_samples[family][i]}, {training_sets_labels[family][i]}\")\n",
    "        print(f\"\\tPrediction: {svm.predict(torch.tensor(training_sets_samples[family][i], dtype=torch.float32))}\")\n",
    "        count += 1\n",
    "        if count == 5:\n",
    "            break\n",
    "\n",
    "# Get the accuracy of the model on the training set\n",
    "correct_predictions = 0\n",
    "for i in range(len(training_sets_labels[family])):\n",
    "    prediction = svm.predict(torch.tensor(training_sets_samples[family][i], dtype=torch.float32))\n",
    "    if (prediction >= 0.5 and training_sets_labels[family][i] == 1) or (prediction < 0.5 and training_sets_labels[family][i] == 0):\n",
    "        correct_predictions += 1\n",
    "accuracy = correct_predictions / len(training_sets_labels[family])\n",
    "print(f\"\\nAccuracy of the model on the training set for family '{family}': {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of the ensemble model on the training set: 0.31331726260144327\n"
     ]
    }
   ],
   "source": [
    "# Get the accuracy of the ensemble model on the training set\n",
    "correct_predictions = 0\n",
    "for i in range(len(dataset_vectors)):\n",
    "    family = ensemble_svm.predict(torch.tensor(dataset_vectors[i], dtype=torch.float32))\n",
    "    if family == dataset_families[i]:\n",
    "        correct_predictions += 1\n",
    "accuracy = correct_predictions / len(dataset_vectors)\n",
    "print(f\"\\nAccuracy of the ensemble model on the training set: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
